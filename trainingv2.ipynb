{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from langwahge.model import Model, loss_accuracy\r\n",
    "from mynn.optimizers.sgd import SGD\r\n",
    "import numpy as np\r\n",
    "import coco_data\r\n",
    "import random\r\n",
    "from noggin import create_plot\r\n",
    "plotter, fig, ax = create_plot(metrics=[\"loss\"], max_fraction_spent_plotting=.75)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = coco_data()\r\n",
    "_, glove, resnet18_features, imgid_to_capid, capid_to_imgid, capid_to_capstr, _ = data.get_self()\r\n",
    "\r\n",
    "triplets = []\r\n",
    "# (caption_id, img_id, confuser_id)\r\n",
    "for key in list(capid_to_imgid.keys()):\r\n",
    "    caption_id = key\r\n",
    "    img_id = capid_to_imgid[key]\r\n",
    "    #values = np.array(list(imgid_to_capid.values()))\r\n",
    "    conf_id = random.choice(list(capid_to_imgid.values()))\r\n",
    "    if conf_id == img_id:\r\n",
    "        conf_id = random.choice(list(capid_to_imgid.values()))\r\n",
    "    triplets.append((caption_id, img_id, conf_id))\r\n",
    "    print(triplets)\r\n",
    "\r\n",
    "#split the data\r\n",
    "split_at = 0.8\r\n",
    "split = int(len(triplets) * split_at)\r\n",
    "train_triplets = triplets[:split] \r\n",
    "test_triplets = triplets[split:]\r\n",
    "\r\n",
    "model = Model(512, 200)\r\n",
    "optim = SGD(model.parameters, learning_rate = 1e-3, momentum =0.9)\r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "num_epochs = 10000\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    indexes = np.arange((len(train_triplets)))\r\n",
    "    np.random.shuffle(indexes)\r\n",
    "    for batch_count in range(0,len(train_triplets)//batch_size):\r\n",
    "        batch_indexes = indexes[batch_count*batch_size: batch_count*(batch_size+1)]\r\n",
    "        img_batch = data.vectorize_image(train_triplets[batch_indexes][1])\r\n",
    "        img_preds = model(img_batch)\r\n",
    "        conf_batch = data.vectorize_image(train_triplets[batch_indexes][2])\r\n",
    "        conf_preds = model(conf_batch)\r\n",
    "        #print(batch)\r\n",
    "        w_captions = data.embed_text(capid_to_capstr[train_triplets[batch_indexes][0]])  #should correspond to the vectors \r\n",
    "        #confuser = model(resnet18_features[random.choice(list(resnet18_features.keys())[:82600])])  \r\n",
    "        w_captions = data.embed_text(np.array([capid_to_capstr[i] for i in train_triplets[batch_indexes][0]]))\r\n",
    "        \r\n",
    "        list_phrases = [capid_to_capstr[i] for i in train_triplets[batch_indexes][0]]\r\n",
    "\r\n",
    "        w_captions = np.array([data.embed_text(i) for i in list_phrases])\r\n",
    "\r\n",
    "        sim_match = w_captions@img_preds\r\n",
    "        sim_confuse = w_captions@conf_preds\r\n",
    "        loss, acc = loss_accuracy(sim_match, sim_confuse, 0.25, len(train_triplets))\r\n",
    "        \r\n",
    "        loss.backward()\r\n",
    "        \r\n",
    "        optim.step()\r\n",
    "        \r\n",
    "        # plotter.set_train_batch({\"loss\" : loss.item()\r\n",
    "        #                          },\r\n",
    "        #                          batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = coco_data()\r\n",
    "_, glove, resnet18_features, imgid_to_capid, capid_to_imgid, capid_to_capstr, _ = data.get_self()\r\n",
    "\r\n",
    "triplets = []\r\n",
    "# (caption_id, img_id, confuser_id)\r\n",
    "for key in list(capid_to_imgid.keys()):\r\n",
    "    caption_id = key\r\n",
    "    img_id = capid_to_imgid[key]\r\n",
    "    #values = np.array(list(imgid_to_capid.values()))\r\n",
    "    conf_id = random.choice(list(capid_to_imgid.values()))\r\n",
    "    if conf_id == img_id:\r\n",
    "        conf_id = random.choice(list(capid_to_imgid.values()))\r\n",
    "    triplets.append((caption_id, img_id, conf_id))\r\n",
    "    print(triplets)\r\n",
    "\r\n",
    "#split the data\r\n",
    "split_at = 0.8\r\n",
    "split = int(len(triplets) * split_at)\r\n",
    "train_triplets = triplets[:split] \r\n",
    "test_triplets = triplets[split:]\r\n",
    "\r\n",
    "model = Model(512, 200)\r\n",
    "optim = SGD(model.parameters, learning_rate = 1e-3, momentum =0.9)\r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "num_epochs = 10000\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    indexes = np.arange((len(train_triplets)))\r\n",
    "    np.random.shuffle(indexes)\r\n",
    "    for batch_count in range(0,len(train_triplets)//batch_size):\r\n",
    "        batch_indexes = indexes[batch_count*batch_size: batch_count*(batch_size+1)]\r\n",
    "        img_batch = data.vectorize_image(train_triplets[batch_indexes][1])\r\n",
    "        img_preds = model(img_batch)\r\n",
    "        conf_batch = data.vectorize_image(train_triplets[batch_indexes][2])\r\n",
    "        conf_preds = model(conf_batch)\r\n",
    "        #print(batch)\r\n",
    "        w_captions = data.embed_text(capid_to_capstr[train_triplets[batch_indexes][0]])  #should correspond to the vectors \r\n",
    "        #confuser = model(resnet18_features[random.choice(list(resnet18_features.keys())[:82600])])  \r\n",
    "        w_captions = data.embed_text(np.array([capid_to_capstr[i] for i in train_triplets[batch_indexes][0]]))\r\n",
    "        \r\n",
    "        list_phrases = [capid_to_capstr[i] for i in train_triplets[batch_indexes][0]]\r\n",
    "\r\n",
    "        w_captions = np.array([data.embed_text(i) for i in list_phrases])\r\n",
    "\r\n",
    "        sim_match = w_captions@img_preds\r\n",
    "        sim_confuse = w_captions@conf_preds\r\n",
    "        loss, acc = loss_accuracy(sim_match, sim_confuse, 0.25, len(train_triplets))\r\n",
    "        \r\n",
    "        loss.backward()\r\n",
    "        \r\n",
    "        optim.step()\r\n",
    "        \r\n",
    "        # plotter.set_train_batch({\"loss\" : loss.item()\r\n",
    "        #                          },\r\n",
    "        #                          batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}