{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from gensim.models import KeyedVectors\n",
    "from collections import Counter\n",
    "import json \n",
    "import re, string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import mygrad as mg\n",
    "\n",
    "class Coco:\n",
    "    punc_regex = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    \n",
    "    def strip_punc(self, corpus):\n",
    "        \"\"\" \n",
    "        Removes all punctuation from a string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            the corpus with all punctuation removed\n",
    "        \"\"\"\n",
    "        # substitute all punctuation marks with \"\"\n",
    "        \n",
    "        return self.punc_regex.sub('', str(corpus))\n",
    "    \n",
    "    def to_counter(self, doc):\n",
    "        \"\"\" \n",
    "        Produce word-count of document, removing all punctuation\n",
    "        and making all the characters lower-cased.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        doc : str\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        collections.Counter\n",
    "            lower-cased word -> count\n",
    "        \"\"\"\n",
    "        return Counter(self.strip_punc(doc).lower().split())\n",
    "\n",
    "    def to_vocab(self, counters, k=None):\n",
    "        \"\"\" \n",
    "        Convert a collection of counters to a sorted list of the top-k most common words \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        counters : Sequence[collections.Counter]\n",
    "            A list of counters; each one is a word tally for a document\n",
    "        \n",
    "        k : Optional[int]\n",
    "            If specified, only the top-k words are returned\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "            A sorted list of the unique strings.\n",
    "        \"\"\"\n",
    "        vocab = Counter()\n",
    "        for counter in counters:\n",
    "            vocab.update(counter)\n",
    "            \n",
    "        return sorted(i for i,j in vocab.most_common(k))\n",
    "\n",
    "    def __init__(self): \n",
    "        \"\"\"\n",
    "        load COCO metadata (json file [\"images\"] [\"annotations\"])\n",
    "        load glove data (dictionary {word : word_embedding})\n",
    "        load in resnet data from resnet18_features.pkl (dictionary {img id : dvector})\n",
    "        \n",
    "        initialize the following attributes:\n",
    "        image-ID -> [cap-ID-1, cap-ID-2, ...]\n",
    "        caption-ID -> image-ID\n",
    "        caption-ID -> caption (e.g. 24 -> \"two dogs on the grass\")\n",
    "        \n",
    "        initialize vocab list and counters list as attributes\n",
    "       \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # load COCO metadata\n",
    "        with Path(r\"C:\\Users\\nicho\\Downloads\\captions_train2014.json\").open() as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        \n",
    "        # load GloVe-200 embeddings\n",
    "        self.glove = KeyedVectors.load_word2vec_format(r\"C:\\Users\\nicho\\Downloads\\glove.6B.200d.txt.w2v\", binary=False)\n",
    "\n",
    "        # load image descriptor vectors\n",
    "        with Path(r\"C:\\Users\\nicho\\Downloads\\resnet18_features.pkl\").open('rb') as f:\n",
    "            self.resnet18_features = pickle.load(f)\n",
    "        \n",
    "        self.imgid_to_capid = {}\n",
    "        self.capid_to_imgid = {}\n",
    "        self.capid_to_capstr = {}\n",
    "\n",
    "        for caption in self.coco_data[\"annotations\"]:\n",
    "            # input caption_id to imgid_to_capid if the img_id key exists\n",
    "            if self.imgid_to_capid.__contains__(caption[\"image_id\"]):\n",
    "                self.imgid_to_capid[caption[\"image_id\"]].append(caption[\"id\"])\n",
    "            # else create new img_id object and create new caption_id list\n",
    "            else:\n",
    "                self.imgid_to_capid[caption[\"image_id\"]] = [caption[\"id\"]]\n",
    "\n",
    "            # input img_id to capid_to_imgid\n",
    "            self.capid_to_imgid[caption[\"id\"]] = caption[\"image_id\"]\n",
    "            # input caption to capid_to_capstr\n",
    "            self.capid_to_capstr[caption[\"id\"]] = caption[\"caption\"]\n",
    "    \n",
    "            # COMPUTING THE IDF\n",
    "            # calculate the total number of captions\n",
    "                N = len(self.coco_data[\"annotations\"])\n",
    "            # get all the words among all the captions\n",
    "                cap_counter = caption.tocounter\n",
    "                for t in cap_counter\n",
    "                append t to vocab\n",
    "            # get the number of captions that word t appears in\n",
    "                \n",
    "        self.vocab = self.to_vocab(self.counters)\n",
    "            \n",
    "    def random_pair(self):\n",
    "        \"\"\"\n",
    "        returns a random caption_string and respective image id\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        None\n",
    "        \n",
    "        Returns \n",
    "        -------\n",
    "        Tuple(int, string)\n",
    "            this contains the random caption_string and respective image id\n",
    "\n",
    "        \"\"\"    \n",
    "        # random respective caption string\n",
    "        captions = self.coco_data[\"annotations\"]\n",
    "        i = random.randint(0, len(captions)) \n",
    "        \n",
    "        caption_info = captions[i]\n",
    "        \n",
    "        return caption_info[\"image_id\"], caption_info[\"caption\"]\n",
    "        \n",
    "    def vectorize_image(self, image_id):\n",
    "        \"\"\"\n",
    "        takes in an image_id and returns the descriptor vector of the image\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        image_id: int\n",
    "            unique integer ID for the image in coco_data\n",
    "        \n",
    "        Returns \n",
    "        -------\n",
    "        image_dvector: np.array shape-(512,)\n",
    "            a descriptor vector of the image as provided by RESNET\n",
    "        \"\"\"\n",
    "        if image_id not in self.resnet18_features.keys():\n",
    "            return np.zeros((512,))\n",
    "        else:\n",
    "            return self.resnet18_features[image_id]\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_idf(self):\n",
    "    \"\"\"\n",
    "        \"\"\" \n",
    "        Given the vocabulary, and the word-counts for each document, computes\n",
    "        the inverse document frequency (IDF) for each term in the vocabulary.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        nt: dict{string, float}\n",
    "            A dictionary storing the IDF for each term in vocab\n",
    "        \"\"\"\n",
    "    \"\"\"\n",
    "        nt = {}\n",
    "        N = len(self.counters)\n",
    "        for t in self.vocab:\n",
    "            total = 0\n",
    "            for counter in self.counters:\n",
    "                if t in counter:\n",
    "                    total += 1\n",
    "\n",
    "            nt[t] = np.log10(N / total)\n",
    "\n",
    "        return nt\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def embed_text(self, text_string):\n",
    "    \"\"\"\n",
    "        \"\"\"\n",
    "        returns normal_text_embedding\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        text_string: String\n",
    "            a caption/query text \n",
    "        \n",
    "        Returns \n",
    "        -------\n",
    "        String\n",
    "            normal text embedding\n",
    "        \"\"\"\n",
    "    \"\"\"\n",
    "        # returns normal_text_embedding\n",
    "        # embed any caption / query text using GloVe-200 embeddings weighted by IDFs of words across captions (pass in either a user's query or existing caption)     \n",
    "        # lowercase, remove punc, tokenize\n",
    "        text_string = self.strip_punc(text_string).lower().split()\n",
    "\n",
    "        text_embedding = []\n",
    "        idf = self.get_idf()\n",
    "        for word in text_string:\n",
    "        # check if each word in given string is in glove[], if not then embedding vector 0\n",
    "        # else get glove vector (200,) for it\n",
    "            glove_vector = 0\n",
    "            if word in self.glove:\n",
    "                glove_vector = self.glove[word]\n",
    "            \n",
    "            idf_word = idf[word]\n",
    "            text_embedding.append(glove_vector * idf_word)\n",
    "\n",
    "        # add all together for the final phrase embed vector, then normalize\n",
    "        normal_text_embedding = mg.sqrt(mg.einsum(\"ij, ij -> i\", text_embedding, text_embedding)).reshape(-1, 1)\n",
    "\n",
    "        # return normal_text_embedding\n",
    "        return normal_text_embedding\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        returns coco_data, glove , resnet18_features, imgid_to_capid, capid_to_imgid, capid_to_capstr, counters\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        None\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        Tuple(dict, dict, dict)\n",
    "            contains coco data, glove data, and resnet data\n",
    "        \"\"\"\n",
    "        return (self.coco_data, self.glove, self.resnet18_features, self.imgid_to_capid, self.capid_to_imgid, self.capid_to_capstr, self.counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE COCO, GLOVE, RESNET DATA\n",
    "coco = Coco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVE DICTIONARIES W/ VARIOUS MAPPINGS\n",
    "coco_data, glove, resnet18_features, imgid_to_capid, capid_to_imgid, capid_to_capstr, counters = coco.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285342 Close up view of some kind of meat with black eyed peas and vegetables.\n"
     ]
    }
   ],
   "source": [
    "# RANDOM IMAGE/CAPTION PAIR\n",
    "img_id, cap_str = coco.random_pair()\n",
    "print(img_id, cap_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.52659881e-01 2.44662285e-01 4.68955003e-03 9.97656345e-01\n",
      "  4.48034406e-01 1.04226187e-01 1.09769598e-01 1.72474837e+00\n",
      "  6.13684841e-02 3.39598179e-01 1.16680288e+00 0.00000000e+00\n",
      "  9.89537597e-01 4.56126511e-01 9.80125368e-01 2.36543894e-01\n",
      "  1.58537340e+00 1.12955976e+00 2.16912460e+00 7.98378289e-02\n",
      "  5.43035030e-01 3.18641007e-01 3.24012011e-01 5.15243292e-01\n",
      "  1.97668564e+00 1.11735791e-01 2.66474628e+00 3.80649209e-01\n",
      "  4.31259036e-01 1.22607911e+00 2.32709438e-01 1.27601123e+00\n",
      "  3.26328486e-01 1.18999168e-01 2.98471391e-01 5.24648488e-01\n",
      "  4.78155017e-01 9.78624046e-01 6.19935244e-02 1.31917453e+00\n",
      "  9.25579488e-01 1.65383920e-01 3.44611704e-01 1.25879526e-01\n",
      "  2.80028768e-02 5.50404489e-01 8.61250013e-02 1.96195054e+00\n",
      "  1.15808356e+00 5.49530447e-01 2.55597681e-01 8.20780098e-01\n",
      "  3.27801585e+00 8.48169327e-02 1.22917974e+00 6.27175689e-01\n",
      "  1.23979859e-01 1.15657175e+00 8.64573598e-01 1.19351327e+00\n",
      "  1.18235362e+00 2.21458942e-01 3.78897712e-02 5.25794804e-01\n",
      "  6.93939686e-01 7.06914485e-01 7.60487318e-01 9.36952382e-02\n",
      "  2.22682858e+00 1.76010057e-01 1.15868866e-01 1.77414268e-02\n",
      "  9.42198113e-02 8.07929277e-01 1.69539905e+00 1.23208880e-01\n",
      "  1.53796554e-01 7.02155650e-01 9.89490271e-01 1.26444936e+00\n",
      "  1.16758108e+00 9.10518348e-01 9.38746870e-01 9.78666961e-01\n",
      "  2.07674772e-01 9.80526507e-01 3.41845602e-01 1.11218274e+00\n",
      "  8.05333778e-02 0.00000000e+00 5.40777862e-01 1.20139349e+00\n",
      "  4.81928587e-01 6.05530381e-01 7.76670873e-01 5.44547796e-01\n",
      "  3.09370965e-01 1.03759634e+00 2.43174374e-01 4.02794510e-01\n",
      "  2.07616615e+00 1.15157795e+00 6.72859401e-02 2.94017375e-01\n",
      "  3.34481806e-01 2.52591163e-01 1.18439347e-01 1.36214495e+00\n",
      "  3.61413419e-01 4.99812931e-01 5.07685006e-01 1.76543593e-01\n",
      "  3.52728814e-01 1.41950846e+00 2.56762743e-01 1.33144057e+00\n",
      "  1.52942294e-03 3.32097501e-01 3.65250111e-01 7.68456459e-01\n",
      "  1.60620004e-01 1.14624463e-01 9.84961033e-01 4.14494544e-01\n",
      "  7.53372192e-01 1.13654006e+00 3.15781027e-01 5.31889439e-01\n",
      "  0.00000000e+00 6.87949359e-01 2.02515528e-01 3.01051214e-02\n",
      "  1.06087156e-01 1.76102266e-01 7.49678731e-01 9.54796672e-02\n",
      "  8.57436061e-01 4.82548863e-01 9.03354943e-01 1.42737061e-01\n",
      "  3.91223013e-01 5.61533459e-02 9.15610433e-01 6.07036710e-01\n",
      "  1.96894124e-01 1.50006309e-01 2.64993440e-02 8.66283476e-02\n",
      "  7.76253417e-02 1.52941990e+00 5.14192522e-01 2.03584027e+00\n",
      "  5.13033476e-03 3.84692401e-01 4.35153067e-01 1.58438671e+00\n",
      "  4.64193668e-04 9.81134325e-02 4.64975715e-01 4.77758765e-01\n",
      "  1.35974571e-01 2.97585696e-01 3.68506956e+00 1.07721589e-03\n",
      "  1.69510603e-01 1.52587175e+00 8.07995260e-01 1.09150276e-01\n",
      "  1.93509802e-01 3.13984799e+00 1.98818013e-01 1.83888364e+00\n",
      "  7.06427515e-01 1.03136480e+00 0.00000000e+00 4.09158736e-01\n",
      "  1.25638568e+00 4.44423221e-02 4.36222218e-02 2.40938306e-01\n",
      "  1.20585012e+00 8.01586390e-01 3.41745287e-01 4.60349303e-03\n",
      "  1.82708025e-01 2.32395864e+00 1.71618253e-01 2.99392611e-01\n",
      "  4.71230179e-01 2.46951103e-01 5.41687846e-01 1.76846772e-01\n",
      "  8.64139020e-01 5.01885414e-02 2.69150317e-01 8.63895655e-01\n",
      "  3.29466492e-01 1.48319170e-01 9.43532065e-02 3.45946491e-01\n",
      "  2.06914759e+00 3.53463352e-01 9.83978748e-01 2.09036693e-02\n",
      "  0.00000000e+00 1.37690501e-03 1.35394692e+00 5.85910492e-02\n",
      "  4.15791050e-02 7.38925755e-01 1.84786189e+00 3.25520754e-01\n",
      "  1.94518656e-01 1.83711410e+00 1.49823284e+00 4.59326684e-01\n",
      "  1.47702366e-01 1.52877200e+00 1.39353639e-02 1.97994366e-01\n",
      "  8.19372535e-01 4.50412989e-01 6.01586878e-01 8.34254742e-01\n",
      "  5.85664734e-02 6.16751462e-02 2.81005323e-01 1.98006070e+00\n",
      "  6.16636932e-01 7.16784954e-01 2.94190869e-02 0.00000000e+00\n",
      "  5.52491248e-01 1.64876747e+00 4.72599268e-01 7.21549392e-01\n",
      "  3.26358527e-02 2.95810729e-01 2.99568295e-01 8.81285787e-01\n",
      "  3.53401572e-01 5.09614468e-01 1.29563466e-01 1.30643606e-01\n",
      "  3.76642442e+00 9.68146026e-02 2.04414986e-02 5.05446911e-01\n",
      "  2.53843737e+00 2.84109783e+00 2.98715800e-01 1.34357703e+00\n",
      "  2.99892396e-01 8.13388526e-02 3.97724867e-01 1.84975430e-01\n",
      "  5.14205635e-01 4.18718958e+00 2.87244201e-01 4.83010530e+00\n",
      "  5.61663389e-01 4.97727364e-01 2.66695842e-02 1.39821339e+00\n",
      "  8.00588191e-01 2.46367529e-01 1.78500926e+00 5.84560692e-01\n",
      "  8.69141817e-01 1.04350448e+00 7.59336829e-01 7.02690840e-01\n",
      "  1.73032093e+00 7.96774983e-01 6.37757778e-01 5.40028691e-01\n",
      "  2.26518655e+00 1.41647637e-01 2.30301231e-01 4.74589586e-01\n",
      "  5.11083543e-01 1.27420127e+00 3.66260767e-01 5.60651906e-02\n",
      "  2.35503122e-01 7.38442719e-01 6.36124611e-02 8.01212490e-01\n",
      "  8.71004090e-02 1.08737767e+00 4.44219083e-01 4.28074121e-01\n",
      "  2.57145077e-01 2.55734976e-02 1.59731579e+00 1.28651619e+00\n",
      "  0.00000000e+00 8.78279924e-01 2.46866159e-02 2.15492177e+00\n",
      "  2.99191922e-01 5.11122048e-01 1.27371237e-01 5.11072755e-01\n",
      "  6.45260990e-01 1.79007864e+00 1.04494214e-01 7.17948914e-01\n",
      "  1.28701377e+00 3.10953975e-01 1.21668863e+00 7.33239710e-01\n",
      "  1.10597527e+00 1.15197815e-01 2.86000550e-01 2.28013277e-01\n",
      "  3.40629429e-01 4.01254624e-01 1.11019325e+00 1.14791191e+00\n",
      "  8.64109695e-02 6.15598381e-01 4.37457919e-01 1.22605085e+00\n",
      "  1.16967261e-01 1.92189419e+00 3.16076934e-01 1.67314065e+00\n",
      "  2.15267688e-01 5.18190920e-01 1.35479176e+00 3.51421785e+00\n",
      "  1.58717549e+00 2.36024231e-01 5.56318700e-01 3.42426211e-01\n",
      "  3.01900536e-01 1.37054646e+00 5.77771068e-01 1.43763080e-01\n",
      "  4.63131577e-01 1.56078711e-01 1.10712183e+00 1.60366404e+00\n",
      "  3.86293143e-01 6.28437579e-01 2.83267975e-01 2.27279425e+00\n",
      "  2.76378453e-01 1.97419524e-01 7.75032630e-03 9.19243544e-02\n",
      "  1.44538218e-02 1.44299662e+00 5.83587527e-01 1.43714988e+00\n",
      "  2.12062150e-01 9.50091481e-01 2.64673877e+00 7.94199109e-02\n",
      "  1.00354099e+00 2.54828066e-01 4.92955625e-01 5.95929027e-01\n",
      "  3.72390330e-01 1.00121349e-01 2.42836505e-01 1.46296576e-01\n",
      "  2.57284492e-01 1.46058857e-01 7.37385321e+00 1.44229650e-01\n",
      "  6.74289107e-01 2.35970795e-01 2.13505831e-02 4.37582403e-01\n",
      "  1.04305685e+00 3.20755951e-02 2.00106215e+00 7.82489479e-01\n",
      "  2.56358242e+00 8.96710396e-01 4.42935452e-02 1.63787246e-01\n",
      "  1.34250522e-01 4.64628887e+00 2.67238915e-01 8.09018135e-01\n",
      "  7.42581666e-01 1.92031205e+00 3.36066186e-02 1.96463332e-01\n",
      "  6.48208141e-01 4.94343996e-01 2.45483470e+00 1.29344240e-01\n",
      "  1.68709683e+00 1.89514551e-02 8.12943518e-01 1.15105784e+00\n",
      "  3.57051873e+00 1.78583932e+00 1.12203336e+00 1.36066154e-01\n",
      "  2.46751711e-01 5.29299676e-01 2.45590401e+00 1.77947432e-02\n",
      "  2.67855000e+00 9.87638906e-02 7.06547558e-01 4.69551623e-01\n",
      "  2.49581799e-01 1.86420143e-01 8.91345024e-01 6.80817902e-01\n",
      "  8.00442323e-03 4.48624909e-01 3.79303604e-01 5.59206009e-01\n",
      "  6.19284868e-01 5.84540129e-01 3.49250942e-01 7.77672231e-02\n",
      "  1.07185793e+00 1.51571231e-02 6.46846667e-02 9.30843174e-01\n",
      "  2.00893641e+00 1.22242130e-01 1.05348647e-01 1.27809018e-01\n",
      "  3.82399106e+00 5.34680188e-01 7.83025324e-01 1.60367370e-01\n",
      "  7.95009434e-01 1.84194839e+00 5.47167182e-01 3.32920313e-01\n",
      "  3.56729627e+00 1.22579658e+00 6.27411067e-01 6.52415216e-01\n",
      "  1.50511646e+00 8.25748265e-01 7.17491984e-01 2.62933582e-01\n",
      "  1.86770833e+00 1.88212529e-01 4.93554950e-01 1.10866773e+00\n",
      "  3.37328315e-01 3.46575558e-01 4.37525094e-01 3.52684945e-01\n",
      "  1.35404635e-02 6.17106855e-01 2.32771611e+00 3.07822138e-01\n",
      "  4.76243114e+00 2.93107294e-02 6.34116650e-01 1.02790415e-01\n",
      "  3.62419218e-01 1.58237979e-01 7.29660019e-02 1.09107447e+00\n",
      "  3.58017176e-01 7.40518153e-01 8.22315216e-01 1.63679704e-01\n",
      "  5.28985076e-02 5.38458645e-01 1.15040791e+00 1.15237951e+00\n",
      "  2.35274777e-01 1.16879307e-01 1.70453057e-01 2.61979192e-01\n",
      "  1.07710846e-01 2.75648594e-01 1.34660220e+00 2.69426644e-01\n",
      "  8.98744226e-01 3.94299537e-01 1.41941518e-01 1.75045028e-01\n",
      "  4.95110929e-01 1.88787386e-01 4.36105824e+00 1.44607449e+00\n",
      "  2.56048858e-01 6.55332282e-02 2.82459445e-02 2.81344318e+00\n",
      "  7.09692240e-02 4.72013950e-01 3.29412413e+00 5.44606566e-01\n",
      "  2.55110955e+00 5.53359628e-01 7.34745204e-01 2.77601862e+00\n",
      "  4.77577746e-01 4.14617568e-01 8.66089880e-01 4.33020353e-01\n",
      "  4.89019662e-01 7.69065678e-01 1.13803279e+00 1.37673393e-01]]\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZING IMAGES\n",
    "img_dvector = coco.vectorize_image(img_id)\n",
    "print(img_dvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING TEXT\n",
    "cap_embed = coco.embed_text(cap_str)\n",
    "print(cap_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
