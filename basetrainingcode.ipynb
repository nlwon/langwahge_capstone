{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a44a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langwahge.model import Model, loss_accuracy\n",
    "from mynn.optimizers.sgd import SGD\n",
    "import numpy as np\n",
    "import coco_data\n",
    "import random\n",
    "from noggin import create_plot\n",
    "plotter, fig, ax = create_plot(metrics=[\"loss\"], max_fraction_spent_plotting=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878da4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = coco_data()\n",
    "_, glove, resnet18_features, imgid_to_capid, capid_to_imgid, capid_to_capstr, _ = data.get_self()\n",
    "\n",
    "triplets = []\n",
    "# (caption_id, img_id, confuser_id)\n",
    "for key, value in capid_to_imgid:\n",
    "    caption_id = key\n",
    "    img_id = value\n",
    "    conf_id = random.choice(list(imgid_to_capid.keys()))\n",
    "    triplets.append((caption_id, img_id, conf_id))\n",
    "\n",
    "#split the data\n",
    "split_at = 0.8\n",
    "split = int(len(triplets) * split_at)\n",
    "train_triplets = triplets[:split] \n",
    "test_triplets = triplets[split:]\n",
    "\n",
    "model = Model(512, 200)\n",
    "optim = SGD(model.parameters, learning_rate = 1e-3, momentum =0.9)\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    indexes = np.arange((len(train_triplets)))\n",
    "    np.random.shuffle(indexes)\n",
    "    for batch_count in range(0,len(train_triplets)//batch_size):\n",
    "        batch_indexes = indexes[batch_count*batch_size: batch_count*(batch_size+1)]\n",
    "        img_batch = data.vectorize_image(train_triplets[batch_indexes][1])\n",
    "        img_preds = model(img_batch)\n",
    "        conf_batch = data.vectorize_image(train_triplets[batch_indexes][2])\n",
    "        conf_preds = model(conf_batch)\n",
    "        #print(batch)\n",
    "        w_captions = data.embed_text(capid_to_capstr[train_triplets[batch_indexes][0]])  #should correspond to the vectors \n",
    "        #confuser = model(resnet18_features[random.choice(list(resnet18_features.keys())[:82600])])  \n",
    "        w_captions = data.embed_text(np.array([capid_to_capstr[i] for i in train_triplets[batch_indexes][0]]))\n",
    "        \n",
    "        list_phrases = [capid_to_capstr[i] for i in train_triplets[batch_indexes][0]]\n",
    "\n",
    "        w_captions = np.array([data.embed_text(i) for i in list_phrases])\n",
    "\n",
    "        sim_match = w_captions@img_preds\n",
    "        sim_confuse = w_captions@conf_preds\n",
    "        loss, acc = loss_accuracy(sim_match, sim_confuse, 0.25, len(train_triplets))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        # plotter.set_train_batch({\"loss\" : loss.item()\n",
    "        #                          },\n",
    "        #                          batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
