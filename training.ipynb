{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from mynn.layers.dense import dense\n",
    "from mygrad.nnet.initializers import glorot_normal\n",
    "from mynn.optimizers.sgd import SGD\n",
    "import random\n",
    "import mygrad as mg\n",
    "from langwahge import *\n",
    "%matplotlib inline\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\" Initializes all of the encoder and decoder layers in our model, setting them\n",
    "        as attributes of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        context_words : int\n",
    "            The number of context words included in our vocabulary\n",
    "            \n",
    "        d : int\n",
    "            The dimensionality of our word embeddings\n",
    "        \"\"\"\n",
    "        # STUDENT CODE HERE\n",
    "        self.encoder = dense(input_dim,output_dim, weight_initializer = glorot_normal, bias = False)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        ''' Passes data as input to our model, performing a \"forward-pass\".\n",
    "        \n",
    "        This allows us to conveniently initialize a model `m` and then send data through it\n",
    "        to be classified by calling `m(x)`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Union[numpy.ndarray, mygrad.Tensor], shape=(M, context_words)\n",
    "            A batch of data consisting of M words from the context matrix,\n",
    "                each tracking the number of co-occurences with `context_words` words.\n",
    "                \n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(M, context_words)\n",
    "            The result of passing the data through borth the encoder and decoder.\n",
    "        '''\n",
    "        # STUDENT CODE HERE\n",
    "        \n",
    "        normal_this = self.encoder(x)\n",
    "        normal = mg.sqrt((normal_this**2).sum(keepdims = True))\n",
    "        return normal \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" A convenience function for getting all the parameters of our model.\n",
    "        \n",
    "        This can be accessed as an attribute, via `model.parameters` \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, ...]\n",
    "            A tuple containing all of the learnable parameters for our model\"\"\"\n",
    "        # STUDENT CODE HERE\n",
    "        return self.encoder.parameters"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nicho\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (database.py, line 144)",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\nicho\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3418\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-10-945a28e4de54>\"\u001b[0m, line \u001b[0;32m6\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from langwahge import *\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\nicho\\Student_Week3_2021\\langwahge_capstone\\langwahge\\__init__.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from .database import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\nicho\\Student_Week3_2021\\langwahge_capstone\\langwahge\\database.py\"\u001b[1;36m, line \u001b[1;32m144\u001b[0m\n\u001b[1;33m    def query_database(){\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def loss_accuracy(sim_match, sim_confuse, threshold, triplets = 0):\n",
    "    #loss = max(0, threshold - (sim_match - sim_confuse))\n",
    "    \n",
    "    loss = mygrad.nnet.losses.margin_ranking_loss(sim_match, sim_confuse, threshold)\n",
    "    #list_to_sum = [1 if sim_match>sim_confuse else 0 for i in triplets]\n",
    "    #acc = sum(list_to_sum)/len(triplets)\n",
    "    return loss#, acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = Model(input_dim = 512, output_dim = 200)\n",
    "optim = SGD(model.parameters, learning_rate = 1e-3, momentum = 0.9)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from noggin import create_plot\n",
    "plotter, fig, ax = create_plot(metrics=[\"loss\"], max_fraction_spent_plotting=.75)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "data = coco_data()\n",
    "coco_data, glove, resnet18_features, imgid_to_capid, capid_to_imgid, capid_to_capstr, counters = data.get_self()\n",
    "#split the data\n",
    "split_at = 0.75\n",
    "keyslist = list(resnet18_features.keys())\n",
    "split = int(len(keyslist)*split_at)\n",
    "training_keys = keyslist[:split]      #if this doesn't work for some reason could just hardcode\n",
    "\n",
    "training_vectors = [resnet18_features[i] for i in training_keys]\n",
    "\n",
    "training_captions_id = [imgid_to_capid[i] for i in training_keys]\n",
    "\n",
    "training_captions = [capid_to_capstr[i] for i in training_captions_id]\n",
    "\n",
    "# test_vectors = resnet18_features[split:82600]\n",
    "# test_captions = \n",
    "\n",
    "testing_keys = keyslist[split:82600]\n",
    "\n",
    "testing_vectors = [resnet18_features[i] for i in testing_keys]\n",
    "\n",
    "testing_captions_id = [imgid_to_capid[i] for i in testing_keys]\n",
    "\n",
    "testing_captions = [capid_to_capstr[i] for i in testing_captions_id]\n",
    "\n",
    "match = 0\n",
    "triplets = 0\n",
    "for epoch in range(10000):\n",
    "    indexes = np.arange((len(training_vectors)))\n",
    "    np.random.shuffle(indexes)\n",
    "    for batch_count in range(0,len(training_vectors)//batch_size):\n",
    "        batch_indexes = indexes[batch_count*batch_size: batch_count*(batch_size+1)]\n",
    "        batch = training_vectors[batch_indexes]  \n",
    "#         print(batch)\n",
    "        w_caption = training_captions[i]  #should correspond to the vectors\n",
    "        prediction = model(batch)\n",
    "        \n",
    "        confuser = model(resnet18_features[random.choice(list(resnet18_features.keys())[:82600])])  \n",
    "        \n",
    "        sim_match = w_caption@prediction\n",
    "        sim_confuse = w_caption@confuser\n",
    "        \n",
    "        if sim_match>sim_confuse:  #accuracy?\n",
    "            match+=1\n",
    "        triplets+=1\n",
    "        \n",
    "        loss = loss_accuracy(sim_match, sim_confuse, 0.25)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        #acc =  np.mean(np.argmax(prediction, axis=1) == batch)\n",
    "        \n",
    "        plotter.set_train_batch({\"loss\" : loss.item()\n",
    "                                 },\n",
    "                                 batch_size=batch_size)\n",
    "accuracy = match/triplets"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'coco_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0053aa35abc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mcoco_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet18_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgid_to_capid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapid_to_imgid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapid_to_capstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#split the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coco_data' is not defined"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEmCAYAAAA3CARoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS6UlEQVR4nO3df4xlZX3H8feHXSj+ihhZjS5QkMLQjQWVX7bROmqrLGlCbbWCRiJqtlSxtokJtEm10cRoiYlR0e2WILGxUqtEsVnFXwyYIrKoyA9xcQsKW0goQrSLqXTZb/84Z831Osucu96ZfZb7fiUT5pzz3HO/+2X3fuY5985zUlVIktSaA/Z1AZIkLcaAkiQ1yYCSJDXJgJIkNcmAkiQ1yYCSJDVpyYBKckmS+5LcsofjSfLBJNuS3JTkedMvU5I0a4bMoC4FTnuU4+uBY/qvDcBHf/2yJEmzbsmAqqprgAceZcgZwMercx1wSJJnTKtASdJsWj2Fc6wF7h7Z3t7vu3d8YJINdLMsDj744BOPOOKIKTz9bNi1axcHHOBbhkPZr8nYr8nYr8ncfvvt91fVmkkfN42AyiL7Fl0/qao2AZsA5ubmauvWrVN4+tmwsLDA/Pz8vi5jv2G/JmO/JmO/JpPkR3vzuGn8CLAdOHxk+zDgnimcV5I0w6YRUFcAZ/ef5ns+8JOq+pXLe5IkTWLJS3xJPgnMA4cm2Q68EzgQoKo2ApuB04FtwM+Ac5arWEnS7FgyoKrqrCWOF/CWqVUkSRKuJCFJapQBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJatKggEpyWpKtSbYluWCR409O8vkk301ya5Jzpl+qJGmWLBlQSVYBFwHrgXXAWUnWjQ17C/C9qjoBmAfen+SgKdcqSZohQ2ZQpwDbquqOqnoYuAw4Y2xMAU9KEuCJwAPAzqlWKkmaKasHjFkL3D2yvR04dWzMh4ErgHuAJwGvrqpd4ydKsgHYALBmzRoWFhb2ouTZtGPHDvs1Afs1Gfs1Gfu1MoYEVBbZV2PbLwduBF4CHA18OcnXq+qnv/Sgqk3AJoC5ubman5+ftN6ZtbCwgP0azn5Nxn5Nxn6tjCGX+LYDh49sH0Y3Uxp1DnB5dbYBdwLHTadESdIsGhJQW4BjkhzVf/DhTLrLeaPuAl4KkOTpwBxwxzQLlSTNliUv8VXVziTnAVcCq4BLqurWJOf2xzcC7wYuTXIz3SXB86vq/mWsW5L0GDfkPSiqajOweWzfxpHv7wFeNt3SJEmzzJUkJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNGhRQSU5LsjXJtiQX7GHMfJIbk9ya5OrplilJmjWrlxqQZBVwEfCHwHZgS5Irqup7I2MOAT4CnFZVdyV52jLVK0maEUNmUKcA26rqjqp6GLgMOGNszGuAy6vqLoCqum+6ZUqSZs2QgFoL3D2yvb3fN+pY4ClJFpJ8K8nZ0ypQkjSblrzEB2SRfbXIeU4EXgo8DvhGkuuq6vZfOlGyAdgAsGbNGhYWFiYueFbt2LHDfk3Afk3Gfk3Gfq2MIQG1HTh8ZPsw4J5FxtxfVQ8BDyW5BjgB+KWAqqpNwCaAubm5mp+f38uyZ8/CwgL2azj7NRn7NRn7tTKGXOLbAhyT5KgkBwFnAleMjfkc8MIkq5M8HjgVuG26pUqSZsmSM6iq2pnkPOBKYBVwSVXdmuTc/vjGqrotyReBm4BdwMVVdctyFi5JemwbcomPqtoMbB7bt3Fs+0LgwumVJkmaZa4kIUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlq0qCASnJakq1JtiW54FHGnZzkkSSvnF6JkqRZtGRAJVkFXASsB9YBZyVZt4dx7wOunHaRkqTZM2QGdQqwraruqKqHgcuAMxYZ91bgM8B9U6xPkjSjhgTUWuDuke3t/b5fSLIWeAWwcXqlSZJm2eoBY7LIvhrb/gBwflU9kiw2vD9RsgHYALBmzRoWFhaGVSl27NhhvyZgvyZjvyZjv1bGkIDaDhw+sn0YcM/YmJOAy/pwOhQ4PcnOqvrs6KCq2gRsApibm6v5+fm9q3oGLSwsYL+Gs1+TsV+TsV8rY0hAbQGOSXIU8F/AmcBrRgdU1VG7v09yKfDv4+EkSdIklgyoqtqZ5Dy6T+etAi6pqluTnNsf930nSdLUDZlBUVWbgc1j+xYNpqp6/a9fliRp1rmShCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJgwIqyWlJtibZluSCRY6/NslN/de1SU6YfqmSpFmyZEAlWQVcBKwH1gFnJVk3NuxO4EVVdTzwbmDTtAuVJM2WITOoU4BtVXVHVT0MXAacMTqgqq6tqgf7zeuAw6ZbpiRp1qweMGYtcPfI9nbg1EcZ/0bgC4sdSLIB2ACwZs0aFhYWhlUpduzYYb8mYL8mY78mY79WxpCAyiL7atGByYvpAuoFix2vqk30l//m5uZqfn5+WJViYWEB+zWc/ZqM/ZqM/VoZQwJqO3D4yPZhwD3jg5IcD1wMrK+qH0+nPEnSrBryHtQW4JgkRyU5CDgTuGJ0QJIjgMuB11XV7dMvU5I0a5acQVXVziTnAVcCq4BLqurWJOf2xzcC7wCeCnwkCcDOqjpp+cqWJD3WDbnER1VtBjaP7ds48v2bgDdNtzRJ0ixzJQlJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMGBVSS05JsTbItyQWLHE+SD/bHb0ryvOmXKkmaJUsGVJJVwEXAemAdcFaSdWPD1gPH9F8bgI9OuU5J0owZMoM6BdhWVXdU1cPAZcAZY2POAD5eneuAQ5I8Y8q1SpJmyOoBY9YCd49sbwdOHTBmLXDv6KAkG+hmWAA/T3LLRNXOtkOB+/d1EfsR+zUZ+zUZ+zWZub150JCAyiL7ai/GUFWbgE0ASW6oqpMGPL+wX5OyX5OxX5OxX5NJcsPePG7IJb7twOEj24cB9+zFGEmSBhsSUFuAY5IcleQg4EzgirExVwBn95/mez7wk6q6d/xEkiQNteQlvqrameQ84EpgFXBJVd2a5Nz++EZgM3A6sA34GXDOgOfetNdVzyb7NRn7NRn7NRn7NZm96leqfuWtIkmS9jlXkpAkNcmAkiQ1adkDymWSJjOgX6/t+3RTkmuTnLAv6mzFUv0aGXdykkeSvHIl62vJkF4lmU9yY5Jbk1y90jW2ZMC/xScn+XyS7/b9GvLe+2NWkkuS3Len32/dq9f6qlq2L7oPVfwn8CzgIOC7wLqxMacDX6D7XarnA99czppa/hrYr98DntJ/v95+PXq/RsZ9je7DPK/c13W32ivgEOB7wBH99tP2dd2N9+tvgff1368BHgAO2te178Oe/T7wPOCWPRyf+LV+uWdQLpM0mSX7VVXXVtWD/eZ1dL9zNquG/P0CeCvwGeC+lSyuMUN69Rrg8qq6C6Cq7Nej96uAJyUJ8ES6gNq5smW2o6quoevBnkz8Wr/cAbWnJZAmHTMrJu3FG+l+IplVS/YryVrgFcDGFayrRUP+bh0LPCXJQpJvJTl7xaprz5B+fRj4bbpFCW4G3lZVu1amvP3SxK/1Q5Y6+nVMbZmkGTG4F0leTBdQL1jWito2pF8fAM6vqke6H3Rn1pBerQZOBF4KPA74RpLrqur25S6uQUP69XLgRuAlwNHAl5N8vap+usy17a8mfq1f7oBymaTJDOpFkuOBi4H1VfXjFaqtRUP6dRJwWR9OhwKnJ9lZVZ9dkQrbMfTf4v1V9RDwUJJrgBOAWQyoIf06B3hvdW+wbEtyJ3AccP3KlLjfmfi1frkv8blM0mSW7FeSI4DLgdfN6E+2o5bsV1UdVVVHVtWRwKeBN89gOMGwf4ufA16YZHWSx9PdteC2Fa6zFUP6dRfdbJMkT6dbsfuOFa1y/zLxa/2yzqBq+ZZJekwa2K93AE8FPtLPCnbWjK6qPLBfYlivquq2JF8EbgJ2ARdX1UzeEmfg3613A5cmuZnu8tX5VTWzt+BI8klgHjg0yXbgncCBsPev9S51JElqkitJSJKaZEBJkppkQEmSmmRASZKaZEBJkppkQKl5SSrJ+0e2357k76d07ktXYoXzJK9KcluSq8b2PzPJp/vvn5Pk9Ck+5yFJ3rzYc0n7AwNK+4OfA3+S5NB9XcioJKsmGP5Gul8SfvHozqq6p6p2B+Rz6H5PZJIaHu13GQ8BfhFQY88lNc+A0v5gJ7AJ+OvxA+MzoCQ7+v/OJ7k6yaeS3J7kvenupXV9kpuTHD1ymj9I8vV+3B/1j1+V5MIkW/p71/z5yHmvSvIvdAuEjtdzVn/+W5K8r9/3Dro1EzcmuXBs/JH92IOAdwGvTnc/plcneUK6e+xsSfKdJGf0j3l9kn9L8nngS0memOSrSb7dP/fuVbffCxzdn+/C3c/Vn+PgJB/rx38n3dqOu899eZIvJvlBkn8Y6celfa03J/mV/xfStC33WnzStFwE3LT7BXOgE+hWm36Abgmai6vqlCRvo7sFx1/1444EXkS34OdVSX4LOJtuKZaTk/wG8B9JvtSPPwV4dlXdOfpkSZ4JvI9uwdUH6cLjj6vqXUleAry9qm5YrNCqergPspOq6rz+fO8BvlZVb0hyCHB9kq/0D/ld4PiqeqCfRb2iqn7azzKvS3IFcEFf53P68x058pRv6Z/3d5Ic19d6bH/sOcBz6WauW5N8CHgasLaqnt2f65A9t12aDmdQ2i/0K0R/HPjLCR62paruraqf0918bnfA3EwXSrt9qqp2VdUP6ILsOOBldOuG3Qh8k255qWP68dePh1PvZGChqv67qnYCn6C7idveehlwQV/DAnAwcER/7MtVtfveOwHek+Qm4Ct0tzB4+hLnfgHwzwBV9X3gR3S32wD4alX9pKr+l+4Ghr9J15dnJflQktMAV+zWsnMGpf3JB4BvAx8b2beT/getdIsTHjRy7Ocj3+8a2d7FL//dH1/vq+he9N9aVVeOHkgyDzy0h/qmfT+PAH9aVVvHajh1rIbX0t3R9cSq+r8kP6QLs6XOvSejfXsEWF1VDyY5ge4WE28B/gx4w6A/hbSXnEFpv9HPGD5F94GD3X5Id0kNujt2HrgXp35VkgP696WeBWylWyT0L5IcCJDk2CRPWOI83wRelOTQ/gMUZwFXT1DH/wBPGtm+EnhrH7wkee4eHvdk4L4+nF5MN+NZ7HyjrqELNvpLe0fQ/bkX1V86PKCqPgP8Hd2tvaVlZUBpf/N+uvs67fZPdKFwPd3tIfY0u3k0W+mC5AvAuf2lrYvpLm99u/9gwT+yxBWH/tYBfwNcBXwX+HZVfW6COq4C1u3+kATdatkH0r33dku/vZhPACcluYEudL7f1/NjuvfObhn/cAbwEWBVupW4/xV4fX8pdE/WAgv95cZL+z+ntKxczVyS1CRnUJKkJhlQkqQmGVCSpCYZUJKkJhlQkqQmGVCSpCYZUJKkJv0/zUnMgNUamSMAAAAASUVORK5CYII="
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#testing\n",
    "length_total = defaultdict(int)\n",
    "length_correct = defaultdict(int)\n",
    "\n",
    "with mg.no_autodiff:\n",
    "    for i in range(10000):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"i = {i}\")\n",
    "        #x, target, sequence = generate_batch(1, 20, 1)\n",
    "        x = test_vectors[i]\n",
    "        output = model(x)\n",
    "\n",
    "        length_total[sequence.size] += 1\n",
    "        if np.all(np.argmax(output, axis=-1) == target):\n",
    "            length_correct[sequence.size] += 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x, y = [], []\n",
    "for i in range(1, 20):\n",
    "    x.append(i)\n",
    "    y.append(length_correct[i] / length_total[i])\n",
    "ax.plot(x, y);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}